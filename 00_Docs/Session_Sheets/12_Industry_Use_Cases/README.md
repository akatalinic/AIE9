# Session 12: üíº¬†Industry Use Cases

üéØ¬†Understand the state of production LLM applications and leading use cases and hear from expert practitioners around the AI Makerspace community

üìö **Learning Outcomes**
- Understand typical use cases for production LLM application throughout industry in general
- Hear from industry practitioners around the AI Makerspace community about what they‚Äôve been building for clients and customers!
- Overview of the Certification Challenge
   
## üìú Recommended Reading
- [State of Agent Engineering](https://www.langchain.com/state-of-agent-engineering) (Jan 2026)
- [How People Use ChatGPT ](https://openai.com/index/how-people-are-using-chatgpt/)(Sept 2025)
- [Anthropic Economic Index report](https://www.anthropic.com/research/anthropic-economic-index-september-2025-report) (Sept 2025)

# üó∫Ô∏è Overview

Welcome to the middle of the course!  We‚Äôre 5 weeks in, and we‚Äôve covered a lot of ground - you all certainly have enough prototyping skill to be dangerous!

It‚Äôs time to align the skills we‚Äôve learned with the specific direction that _you‚Äôre aiming at_.

What are your goals for 2026? How can you build üèóÔ∏è, ship üö¢, and share üöÄ¬†your way towards achieving them?

The Certification Challenge invites you to take a step towards them.

> üí° Remember, *you know enough already to be dangerous*. You already know enough of the concepts and code you need to build, ship, and share production AI applications

It's time to put your skills to the test!

# Setting Expectations

During Cohort 8, here is how the numbers shook out. It took an average of 26.2 hours for people to complete the challenge. This is up slightly from 23.2 hours on average in Cohort 7.

<p align="center">
  <img src="ccChart.webp" width="80%" />
</p>

This type of work, though - scoping a problem, creating a solution to that problem that solves a specific pain point for real customers or stakeholders, and engineering it for scale from day 1, is extremely valuable work. **This kind of pilot project work is easily worth $10-20k for as a solo consultant**. Of course, finding the right buyer and getting them to buy is a separate issue...

It is also the kind of work that, after you take a few shots on goal, will become faster and faster for you to knock out.

Finally, it‚Äôs worth noting that [Certified AI Engineers](https://aimakerspace.io/graduates/) not only are at the top of hiring lists within our network, but many of them have started their own startups or solo consultancies and still collaborate with us when it comes to generating new business, hiring talent, and serving as enterprise trainers.

What is in your future as an AI Engineer or AI Engineering Leader?

Whatever it is, it will start with the first question of The Certification Challenge: What are you building, and why?

But what should you build today, and why?

# What Not To Build

The first way to answer a "what should you do" question is to answer its logical opposite.

You should NOT:

- Build anything that ChatGPT or Claude can do out of the box
- Focus on building things with only publicly available data
- Think that vibe coding a frontend can differentiate your application
- Forget about the cycles of conversation turns and the role of memory in user experience
- Forget to add "agents" to your idea when selling it (even if it is simply using a simple agentic search or RAG tool)
- Cast aside _your specific industry expertise_
- Fail to plan for a positive feedback loop of usage -> data from usage -> better performance -> more usage -> more data -> better ...
- Recreate _any wheels_ from scratch that you can get off the shelf

# üï¥Ô∏è¬†Industry Use Cases

ROI now. More pilots now. More of them in production now.

In 2026, enterprises are competing more than ever. They want to win in the marketplace. They want to defeat their competition and capture the market. They need people like you to help them do it.

In 2026, even big governments in the U.S. and around the world are saying that the time is NOW to implement AI projects. No one starts a talk at a conference and asks, "Raise your hand if you've used ChatGPT, Gemini, or Claude?!" Even the safest industries are moving faster than ever and trying to make "fail fast - it's OK" part of their AI strategy.

The keyword last year for those building at the edge was something like `productivity`.

The keyword this year goes further; it's something like `agentic AI leadership`. Companies want to go beyond simple productivity hacks and automations into a space of more transformational change.

As we've learned, a Deep Research system is a multi-agent system. We can build these ourselves and tailor them to our use cases. Just 18 months ago, building a system like this _was transformational change_. The number 1 use case for agents was research and summarization, according to LangChain‚Äôs 2024 [State of AI Agents](https://www.langchain.com/stateofaiagents). This capability to search and re-search has now been built into all of the leading LLM products.

Going up a level, we might ask: where do we plug a deep research tool into a workflow that exists in our organization? How might we tailor it to our company or use case? 

We're moving beyond _single employees that do more_ to _smaller teams that do more_.

If product management tactics can be implemented 10x faster, and code - whether backend or frontend can be written 10-100x faster - why do we need a ton of people to do big things?

The answer is that we don't. We can go beyond productivity with agentic AI, _properly wielded by everyone in our organization_.

The caveat of trying to do more transformational things with agents is that there are risks. These risks exist on both the business and technical sides.

If we, as AI Engineers, can help manage those risks, the ROI and upside for our companies (and for us!) can be quite large.

## How Things Have Been Going

From LangChain's State of AI Engineering (Jan 2026)

>Key findings:
> - **Production momentum is real**, with 57% of respondents having agents in production, with large enterprises leading in adoption
> - **Quality is the production killer**, with 32% citing it as a top barrier. Meanwhile, cost concerns dropped from last year
> - **Observability is table stakes**. Nearly 89% of respondents have implemented observability for their agents, outpacing evals adoption at 52%.
> - Using **multiple models is the norm**. OpenAI leads with their GPT models but Gemini, Claude, and open source models see significant adoption. Fine-tuning has not been widely adopted.

We're hearing things like "Coding is largely solved" from the [Head of Claude Code](https://www.youtube.com/watch?v=We7BZVKbCVw).

As [KPMG put it](https://kpmg.com/us/en/media/news/q2-ai-pulse-2025-agents-move-beyond-experimentation.html) in June of 2025: ‚ÄúAI-agent strategies are moving past the experimentation phase,‚Äù and that ‚ÄúAI-agents transition from tools to teammates.‚Äù They also noted that ‚ÄúROI focus shifts amid data challenges and need for broad expertise.‚Äù *This means that ROI and scoping business problems worth solving is more important than ever*, and a far cry from May 2024 when McKinsey broke the business-value issue down in one sentence: ‚Äú[Gen AI starts to generate value](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai).‚Äù 

It seems that KPMG captured the zeitgeist quite well at that time - the transition from hype to real business value is upon us.

We have Deep Research, we have Claude Code, we have other crazy things on the horizon. 

More practically, Generative AI tools are being rolled out as organizational resources everywhere. The tools are available to humans, but which humans will put them to work, help the companies develop a competitive edge? In 2026, we have 10x marketing managers, 10x product managers, 10-100x software engineers & data scientists. What will you be?

>AI offers an unprecedented opportunity for employees to harness the data and context around them. 2026 will be the year when every employee can go from guessing to knowing‚Äîbut only if their organizations invest in the skills to make it possible.‚Äù ~ Andrew Milo, Global Director, Customer Training, Cloud Learning Services, Google Cloud [Ref]
